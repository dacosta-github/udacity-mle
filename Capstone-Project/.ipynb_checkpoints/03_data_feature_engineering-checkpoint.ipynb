{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Engineer Nanodegree\n",
    "\n",
    "## Project: Complaints Text Classification \n",
    "\n",
    "### 03. Data Pre-Preprocessing & Data Feature Enginnering\n",
    "\n",
    "At this stage of the project, after the data exploration stage where I understand how the data is distributed, I'll work this data set in order to have a final data set for the project. I'll apply here some mechanisms to reduce in the data set, trying to reduce it by 90%, because this is too big to be worked on locally in my laptopt.\n",
    "\n",
    "After preparing the final dataset, I'll transform the features so that they can be used in our model. This step includes the process of loading dataset and performing basic data exploration and preprocessing. The dataset is then splitted into training and test sets;\n",
    "\n",
    "I prepared this notebook for the data preparation and feature engineering phase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1 - Importing packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import randint\n",
    "import os\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "#Seed - https://www.mikulskibartosz.name/how-to-set-the-global-random_state-in-scikit-learn/\n",
    "seed = 90 #np.random.seed(31415)\n",
    "\n",
    "\n",
    "# Pre-Processing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from langdetect import detect\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from stop_words import get_stop_words\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# EDA\n",
    "import sweetviz as sv\n",
    "from pandas_profiling import ProfileReport as ppr\n",
    "\n",
    "# Ploting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Classifiers\n",
    "from sklearn import model_selection\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "\n",
    "# Metrics to score classifiers\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, auc, roc_curve, log_loss\n",
    "\n",
    "# Data splitting, CV\n",
    "from sklearn.model_selection import train_test_split,cross_val_score, KFold, StratifiedKFold\n",
    "\n",
    "# My libraries:\n",
    "import utilities.helpers as helpers\n",
    "import source_sklearn.train as train\n",
    "\n",
    "# Warnings;\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2 - Load worked dataset and copy to a dataframe with pandas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder\n",
    "dest_folder = '../Capstone-Project/classification_data/';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_complaints_pre_final pickle file loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load pickle file to a data frame\n",
    "file_name = 'df_complaints_pre_final'\n",
    "\n",
    "df_complaints = helpers.load_pickle(dest_folder,file_name);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complaints = df_complaints.copy();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>complaint_id</th>\n",
       "      <td>3384392</td>\n",
       "      <td>3433198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>complaint_text</th>\n",
       "      <td>transworld systems inc. \\nis trying to collect...</td>\n",
       "      <td>Over the past 2 weeks, I have been receiving e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>issue</th>\n",
       "      <td>Attempts to collect debt not owed</td>\n",
       "      <td>Communication tactics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub_issue</th>\n",
       "      <td>Debt is not yours</td>\n",
       "      <td>Frequent or repeated calls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product</th>\n",
       "      <td>Debt collection</td>\n",
       "      <td>Debt collection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub_product</th>\n",
       "      <td>I do not know</td>\n",
       "      <td>I do not know</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company</th>\n",
       "      <td>TRANSWORLD SYSTEMS INC</td>\n",
       "      <td>Diversified Consultants, Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>complaint_text_length</th>\n",
       "      <td>98</td>\n",
       "      <td>395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_length</th>\n",
       "      <td>6.61471</td>\n",
       "      <td>8.62571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                       0  \\\n",
       "complaint_id                                                     3384392   \n",
       "complaint_text         transworld systems inc. \\nis trying to collect...   \n",
       "issue                                  Attempts to collect debt not owed   \n",
       "sub_issue                                              Debt is not yours   \n",
       "product                                                  Debt collection   \n",
       "sub_product                                                I do not know   \n",
       "company                                           TRANSWORLD SYSTEMS INC   \n",
       "complaint_text_length                                                 98   \n",
       "log_length                                                       6.61471   \n",
       "\n",
       "                                                                       3  \n",
       "complaint_id                                                     3433198  \n",
       "complaint_text         Over the past 2 weeks, I have been receiving e...  \n",
       "issue                                              Communication tactics  \n",
       "sub_issue                                     Frequent or repeated calls  \n",
       "product                                                  Debt collection  \n",
       "sub_product                                                I do not know  \n",
       "company                                    Diversified Consultants, Inc.  \n",
       "complaint_text_length                                                395  \n",
       "log_length                                                       8.62571  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_complaints.head(2).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3 - Data consolidation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll prepare our final data set, and for that I consider the following product consolidation, which I mentioned earlier.\n",
    "\n",
    "* `Credit reporting, credit repair services, or other personal consumer reportsâ€™ --> 'Credit reporting, repair, or other'\n",
    "* `Credit reporting`: `Credit reporting, repair, or other`\n",
    "* `Credit card` --> `Credit card or prepaid card`\n",
    "* `Prepaid card` --> `Credit card or prepaid card`\n",
    "* `Money transfer` --> `Money transfer, virtual currency, or money service`\n",
    "* `Virtual currency` --> `Money transfer, virtual currency, or money service`\n",
    "* `Payday loan, title loan, or personal loan` --> `Loan`\n",
    "* `Student loan` --> `Loan`\n",
    "* `Consumer Loan` --> `Loan`\n",
    "* `Payday loan` --> `Loan`\n",
    "* `Vehicle loan or lease` --> `Loan`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# product consolidation\n",
    "df_complaints['product_consolidation'] = df_complaints['product']\n",
    "\n",
    "# Renaming products\n",
    "df_complaints.replace({'product_consolidation': \n",
    "             {\n",
    "                'Credit reporting, credit repair services, or other personal consumer reports': \n",
    "                'Credit reporting, repair, or other', \n",
    "                'Credit reporting': 'Credit reporting, repair, or other',\n",
    "                'Credit card': 'Credit card or prepaid card',\n",
    "                'Prepaid card': 'Credit card or prepaid card',\n",
    "                'Money transfers': 'Money transfer, virtual currency, or money service',\n",
    "                'Virtual currency': 'Money transfer, virtual currency, or money service',\n",
    "                'Payday loan, title loan, or personal loan':'Loan',\n",
    "                'Student loan': 'Loan',\n",
    "                'Consumer Loan':'Loan',\n",
    "                'Payday loan':'Loan',\n",
    "                'Vehicle loan or lease': 'Loan'}\n",
    "                }, \n",
    "            inplace= True);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product_consolidation\n",
      "Credit reporting, repair, or other                    248281\n",
      "Debt collection                                       125741\n",
      "Mortgage                                               70602\n",
      "Credit card or prepaid card                            65007\n",
      "Loan                                                   57500\n",
      "Checking or savings account                            26070\n",
      "Bank account or service                                14885\n",
      "Money transfer, virtual currency, or money service     12969\n",
      "Other financial service                                  292\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Number of Complaints in each Product\n",
    "product_consolidation_balanced = (df_complaints.groupby('product_consolidation').size()).sort_values(ascending = False)\n",
    "print(product_consolidation_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 9 artists>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Product distribution \n",
    "group = ['product_consolidation']\n",
    "counts = df_complaints.groupby(group).size().reset_index(name=\"Counts\")\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.bar(range(len(counts)), counts['Counts'], color = 'blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4 - Label-Encoding preparation**\n",
    "\n",
    "Considering the algorithms we will use, it is important to create a calculated column encoding the `product` as an integer, because categorical variables are better represented as integers.\n",
    "\n",
    "We have verified that the `product` column in the data, contains string (categorical values), and to prepare them for the extraction of features, I'll want to convert them into numeric values, in a coherent way. \n",
    "In practice I try to assign a new unique-identifier to each different product."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approaches to convert categorical values to numerical:Â¶\n",
    "1. `Label-Encoding`: It can only be applied to target variable.\n",
    "2. `One-Hot-Encoding`: It's applied to training variables.\n",
    "3. `Find & Replace`: Find categorical values & replace them with a numerical value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label-Encoding: It can only be applied to target variable, in this case new variable product_consolidation .\n",
    "encoder = LabelEncoder();\n",
    "\n",
    "df_complaints['product_consolidation_label'] = encoder.fit_transform(df_complaints['product_consolidation'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product_consolidation_label\n",
      "3    248281\n",
      "4    125741\n",
      "7     70602\n",
      "2     65007\n",
      "5     57500\n",
      "1     26070\n",
      "0     14885\n",
      "6     12969\n",
      "8       292\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Number of Complaints in each Product\n",
    "product_consolidation_balanced = (df_complaints.groupby('product_consolidation_label').size().sort_values()).sort_values(ascending = False)\n",
    "print(product_consolidation_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Correlations\n",
    "## df_complaints.corr()\n",
    "corrMatrix = df_complaints.corr()\n",
    "sns.heatmap(corrMatrix, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>complaint_id</th>\n",
       "      <td>3384392</td>\n",
       "      <td>3433198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>complaint_text</th>\n",
       "      <td>transworld systems inc. \\nis trying to collect...</td>\n",
       "      <td>Over the past 2 weeks, I have been receiving e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>issue</th>\n",
       "      <td>Attempts to collect debt not owed</td>\n",
       "      <td>Communication tactics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub_issue</th>\n",
       "      <td>Debt is not yours</td>\n",
       "      <td>Frequent or repeated calls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product</th>\n",
       "      <td>Debt collection</td>\n",
       "      <td>Debt collection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub_product</th>\n",
       "      <td>I do not know</td>\n",
       "      <td>I do not know</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company</th>\n",
       "      <td>TRANSWORLD SYSTEMS INC</td>\n",
       "      <td>Diversified Consultants, Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>complaint_text_length</th>\n",
       "      <td>98</td>\n",
       "      <td>395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_length</th>\n",
       "      <td>6.61471</td>\n",
       "      <td>8.62571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_consolidation</th>\n",
       "      <td>Debt collection</td>\n",
       "      <td>Debt collection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_consolidation_label</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                             0  \\\n",
       "complaint_id                                                           3384392   \n",
       "complaint_text               transworld systems inc. \\nis trying to collect...   \n",
       "issue                                        Attempts to collect debt not owed   \n",
       "sub_issue                                                    Debt is not yours   \n",
       "product                                                        Debt collection   \n",
       "sub_product                                                      I do not know   \n",
       "company                                                 TRANSWORLD SYSTEMS INC   \n",
       "complaint_text_length                                                       98   \n",
       "log_length                                                             6.61471   \n",
       "product_consolidation                                          Debt collection   \n",
       "product_consolidation_label                                                  4   \n",
       "\n",
       "                                                                             3  \n",
       "complaint_id                                                           3433198  \n",
       "complaint_text               Over the past 2 weeks, I have been receiving e...  \n",
       "issue                                                    Communication tactics  \n",
       "sub_issue                                           Frequent or repeated calls  \n",
       "product                                                        Debt collection  \n",
       "sub_product                                                      I do not know  \n",
       "company                                          Diversified Consultants, Inc.  \n",
       "complaint_text_length                                                      395  \n",
       "log_length                                                             8.62571  \n",
       "product_consolidation                                          Debt collection  \n",
       "product_consolidation_label                                                  4  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_complaints.head(2).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4 - Define final dataset and reduce them**\n",
    "\n",
    "Once I have the consolidated data, I'll transform the final data set, selecting only those columns that are of interest for the purpose of this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe with 3 important columns\n",
    "df_complaints_pre_final = df_complaints[['complaint_text', 'product_consolidation', 'product_consolidation_label']]\n",
    "\n",
    "df_complaints_pre_final = df_complaints_pre_final.rename(index=str, columns={\"product_consolidation\": \"product\", \"complaint_text\": \"complaint_text\", 'product_consolidation_label':'product_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complaints_pre_final.head(2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product\n",
      "Credit reporting, repair, or other                    248281\n",
      "Debt collection                                       125741\n",
      "Mortgage                                               70602\n",
      "Credit card or prepaid card                            65007\n",
      "Loan                                                   57500\n",
      "Checking or savings account                            26070\n",
      "Bank account or service                                14885\n",
      "Money transfer, virtual currency, or money service     12969\n",
      "Other financial service                                  292\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Number of Complaints in each Product\n",
    "product_balanced = (df_complaints_pre_final.groupby('product').size()).sort_values(ascending = False)\n",
    "print(product_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before reduce dataset \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(621347, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Before reduce dataset ')  \n",
    "df_complaints_pre_final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the volume of data that exists for each `product`, I'll reduce this dataset (**into 97% of the data**).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac = 0.97\n",
    "\n",
    "df_complaints_final = helpers.reduce_dataset(df_complaints_pre_final, 'product','Credit reporting, repair, or other', frac);\n",
    "df_complaints_final = helpers.reduce_dataset(df_complaints_final, 'product','Debt collection', frac);\n",
    "df_complaints_final = helpers.reduce_dataset(df_complaints_final, 'product','Mortgage', frac);\n",
    "df_complaints_final = helpers.reduce_dataset(df_complaints_final, 'product','Credit card or prepaid card', frac);\n",
    "df_complaints_final = helpers.reduce_dataset(df_complaints_final, 'product','Loan', frac);\n",
    "df_complaints_final = helpers.reduce_dataset(df_complaints_final, 'product','Checking or savings account', frac);\n",
    "df_complaints_final = helpers.reduce_dataset(df_complaints_final, 'product','Bank account or service', frac);\n",
    "\n",
    "df_complaints = df_complaints_final.copy();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After reduce dataset \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(31503, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('After reduce dataset ')  \n",
    "df_complaints.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 31503 entries, 26 to 1827272\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   complaint_text  31503 non-null  object\n",
      " 1   product         31503 non-null  object\n",
      " 2   product_id      31503 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 984.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_complaints_final.info();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>complaint_text</th>\n",
       "      <th>product</th>\n",
       "      <th>product_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>I was sold access to an event digitally, of wh...</td>\n",
       "      <td>Money transfer, virtual currency, or money ser...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>On XX/XX/XXXX, I purchased two {$500.00} visa ...</td>\n",
       "      <td>Credit card or prepaid card</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>On XX/XX/XXXX/2016, I was excited to go in and...</td>\n",
       "      <td>Loan</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>Small business ( checking and savings ) ( corp...</td>\n",
       "      <td>Checking or savings account</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>I had never heard of Mariner Finance before to...</td>\n",
       "      <td>Loan</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        complaint_text  \\\n",
       "26   I was sold access to an event digitally, of wh...   \n",
       "217  On XX/XX/XXXX, I purchased two {$500.00} visa ...   \n",
       "425  On XX/XX/XXXX/2016, I was excited to go in and...   \n",
       "448  Small business ( checking and savings ) ( corp...   \n",
       "467  I had never heard of Mariner Finance before to...   \n",
       "\n",
       "                                               product  product_id  \n",
       "26   Money transfer, virtual currency, or money ser...           6  \n",
       "217                        Credit card or prepaid card           2  \n",
       "425                                               Loan           5  \n",
       "448                        Checking or savings account           1  \n",
       "467                                               Loan           5  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_complaints_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll create specific datasets and dictionaries, for the features and for the labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- PRODUCTS ~ LABELS ------------\n",
      "product_id  product                                           \n",
      "6           Money transfer, virtual currency, or money service    12969\n",
      "3           Credit reporting, repair, or other                     7448\n",
      "4           Debt collection                                        3772\n",
      "7           Mortgage                                               2118\n",
      "2           Credit card or prepaid card                            1950\n",
      "5           Loan                                                   1725\n",
      "1           Checking or savings account                             782\n",
      "0           Bank account or service                                 447\n",
      "8           Other financial service                                 292\n",
      "dtype: int64\n",
      "\n",
      "------------- DIC. PRODUCTS ~ Dic. LABELS ------------\n",
      "\n",
      "{0: 'Bank account or service', 1: 'Checking or savings account', 2: 'Credit card or prepaid card', 3: 'Credit reporting, repair, or other', 4: 'Debt collection', 5: 'Loan', 6: 'Money transfer, virtual currency, or money service', 7: 'Mortgage', 8: 'Other financial service'}\n",
      "\n",
      "{0: 'Bank account or service', 1: 'Checking or savings account', 2: 'Credit card or prepaid card', 3: 'Credit reporting, repair, or other', 4: 'Debt collection', 5: 'Loan', 6: 'Money transfer, virtual currency, or money service', 7: 'Mortgage', 8: 'Other financial service'}\n",
      "\n",
      "\n",
      "------------- COMPLAINTS ~ FEATURES ------------\n",
      "                                            complaint_text\n",
      "26       I was sold access to an event digitally, of wh...\n",
      "217      On XX/XX/XXXX, I purchased two {$500.00} visa ...\n",
      "425      On XX/XX/XXXX/2016, I was excited to go in and...\n",
      "448      Small business ( checking and savings ) ( corp...\n",
      "467      I had never heard of Mariner Finance before to...\n",
      "...                                                    ...\n",
      "1826949  I applied for and was approved for the XXXX Cr...\n",
      "1826979  I have an online bank account with HSBC. My AT...\n",
      "1827014  I just logged on to a credit site to join and ...\n",
      "1827019  I recieved a collections call from an unknown ...\n",
      "1827272  On XX/XX/2019 I initiated a transfer from my X...\n",
      "\n",
      "[31503 rows x 1 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_products = df_complaints_final[['product']]\n",
    "products = df_complaints_final['product']\n",
    "\n",
    "df_products_id = df_complaints_final[['product_id']]\n",
    "products_id = df_complaints_final['product_id']\n",
    "\n",
    "# Labels\n",
    "df_labels = df_complaints_final[['product_id', 'product']].drop_duplicates().sort_values(by = 'product_id', ascending = True)\n",
    "print('------------- PRODUCTS ~ LABELS ------------')\n",
    "#print(df_products)\n",
    "print((df_complaints_final.groupby(['product_id', 'product']).size()).sort_values(ascending = False))\n",
    "print('')\n",
    "\n",
    "# Dictionaries for labels\n",
    "print('------------- DIC. PRODUCTS ~ Dic. LABELS ------------')\n",
    "product_to_id = dict(df_labels.values) # key-value pair\n",
    "id_to_product = dict(df_labels[['product_id', 'product']].values)  #key-value pair\n",
    "print('')\n",
    "print(product_to_id)\n",
    "print('')\n",
    "print(id_to_product)\n",
    "print('')\n",
    "      \n",
    "# Features\n",
    "df_pre_features  = df_complaints_final[['complaint_text']]\n",
    "pre_features  = df_complaints_final['complaint_text']\n",
    "print('')\n",
    "print('------------- COMPLAINTS ~ FEATURES ------------')\n",
    "print(df_pre_features)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickling our subsetted dataframe\n",
    "file_name = 'df_complaints_final'\n",
    "helpers.save_pickle(dest_folder, df_complaints_final, file_name);\n",
    "\n",
    "file_name = 'df_pre_features'\n",
    "helpers.save_pickle(dest_folder, df_pre_features, file_name);\n",
    "\n",
    "file_name = 'df_products'\n",
    "helpers.save_pickle(dest_folder, df_products, file_name);\n",
    "\n",
    "file_name = 'df_products_id'\n",
    "helpers.save_pickle(dest_folder, df_products_id, file_name);\n",
    "\n",
    "file_name = 'df_labels'\n",
    "helpers.save_pickle(dest_folder, df_labels, file_name);\n",
    "\n",
    "file_name = 'products'\n",
    "helpers.save_pickle(dest_folder, products, file_name);\n",
    "\n",
    "file_name = 'pre_features'\n",
    "helpers.save_pickle(dest_folder, pre_features, file_name);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4 - Final data set analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bc6dc75ad3945fea8c9deb80cd795aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Summarize dataset'), FloatProgress(value=0.0, max=18.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "484ad8b49bdf402bb43b5da94dd84abf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Generate report structure'), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PANDAS_REPORT_COMPLAINTS = ppr(df_complaints_final, title=\"Pandas Profiling Reporting - COMPLAINTS\")\n",
    "PANDAS_REPORT_COMPLAINTS.to_notebook_iframe();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5 - Text processing and Split Data**\n",
    "\n",
    "The aim of this project is the construction of a complaints classifier. And this task is a comparison text; a text which looks at a given complaint and product text, compares them and predicts whether a complaint has been classified from the product. To make this comparison effective, and train a classifier, I'll  have to do a few more things: \n",
    "\n",
    "First, I'll clean pre-process all the complaints to be easily compared with the products:\n",
    "\n",
    "1. converting all letters to lower\n",
    "2. converting numbers into words \n",
    "3. removing white spaces\n",
    "4. expanding some abbreviations\n",
    "5. removing non ascii\n",
    "6. remove wrong convertion characters from text\n",
    "7. removing xxx since it will be treated as importand words by tf-idf vectorization\n",
    "\n",
    "Then I'll divide our data into `train` data and `test` data, so that they can be used to train a classifier and evaluate it, respectively.\n",
    "\n",
    "The first 80% is training and the last 20% is test set. If we set the shuffle parameter to True, the data will be randomly split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36m__future__\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m print_function\n",
      "\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpandas\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpd\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mutilities\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mhelpers\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mhelpers\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mexternals\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mfeature_extraction\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mtext\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m TfidfVectorizer\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mfeature_extraction\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mtext\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m CountVectorizer\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mfeature_extraction\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mtext\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m TfidfTransformer\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mfeature_selection\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m chi2\n",
      "\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mnaive_bayes\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m GaussianNB, MultinomialNB\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mlinear_model\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m LogisticRegression\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mneighbors\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m KNeighborsClassifier\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mtree\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m DecisionTreeClassifier\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mensemble\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m RandomForestClassifier\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36msvm\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m LinearSVC, SVC\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m model_selection\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mmodel_selection\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m train_test_split, StratifiedKFold, cross_val_score, cross_validate\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtime\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m time\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32msplit_data\u001b[39;49;00m(df_x, df_y, is_clean: \u001b[36mbool\u001b[39;49;00m, is_shuffle: \u001b[36mbool\u001b[39;49;00m, seed: \u001b[36mint\u001b[39;49;00m):\n",
      "    \u001b[33m\"\"\"\u001b[39;49;00m\n",
      "\u001b[33m    This function allows the split data \u001b[39;49;00m\n",
      "\u001b[33m        param df: data set\u001b[39;49;00m\n",
      "\u001b[33m        param is_clean = to clean?\u001b[39;49;00m\n",
      "\u001b[33m        param is_shuffle = shuffle split data\u001b[39;49;00m\n",
      "\u001b[33m        param seed = cross-validation generator or an iterabl k-fold 5.\u001b[39;49;00m\n",
      "\u001b[33m    \"\"\"\u001b[39;49;00m\n",
      "    \u001b[37m# Set the number of testing points\u001b[39;49;00m\n",
      "    \u001b[34mif\u001b[39;49;00m is_clean:\n",
      "        X_all = df_x.map(\u001b[34mlambda\u001b[39;49;00m x: helpers.clean_text(x))\n",
      "    \u001b[34melse\u001b[39;49;00m:\n",
      "        X_all = df_x \u001b[37m#features\u001b[39;49;00m\n",
      "\n",
      "    y_all = df_y \u001b[37m#label\u001b[39;49;00m\n",
      "    \n",
      "    \u001b[37m#Set the number of testing points\u001b[39;49;00m\n",
      "    \u001b[34mif\u001b[39;49;00m is_shuffle:\n",
      "        X_train, X_test, y_train, y_test = train_test_split(\n",
      "                                                X_all, \n",
      "                                                y_all, \n",
      "                                                test_size=\u001b[34m0.2\u001b[39;49;00m,   \u001b[37m# 80% train/cv, 20% test (5 CV)\u001b[39;49;00m\n",
      "                                                stratify=y_all,\n",
      "                                                random_state=seed,\n",
      "                                                shuffle=\u001b[34mTrue\u001b[39;49;00m)\n",
      "        \u001b[37m# Shuffle and split the dataset into the number of training and testing points above\u001b[39;49;00m\n",
      "    \u001b[34melse\u001b[39;49;00m:\n",
      "        X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, \n",
      "                                                    test_size=\u001b[34m0.2\u001b[39;49;00m,   \u001b[37m# 80% train/cv, 20% test\u001b[39;49;00m\n",
      "                                                    random_state=seed,\n",
      "                                                   )\n",
      "        \n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mX shape:\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, X_all.shape, \u001b[33m'\u001b[39;49;00m\u001b[33my shape:\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, y_all.shape, \u001b[33m'\u001b[39;49;00m\u001b[33mX_train:\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, X_train.shape, \u001b[33m'\u001b[39;49;00m\u001b[33my_train:\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, y_train.shape,\u001b[33m'\u001b[39;49;00m\u001b[33mX_test:\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, X_test.shape, \u001b[33m'\u001b[39;49;00m\u001b[33my_test:\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, y_test.shape)\n",
      "\n",
      "    \u001b[34mreturn\u001b[39;49;00m  X_train, X_test, y_train, y_test;\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mcv_metric_scores\u001b[39;49;00m(X_train , y_train, n_splits, seed, model_type) -> pd.DataFrame:\n",
      "    \u001b[33m\"\"\"\u001b[39;49;00m\n",
      "\u001b[33m    Function that receives the data splited to train several models, returns the metrics for each one.        \u001b[39;49;00m\n",
      "\u001b[33m        :param X_train: training split\u001b[39;49;00m\n",
      "\u001b[33m        :param y_train: training target vector\u001b[39;49;00m\n",
      "\u001b[33m        :return: DataFrame of predictions\u001b[39;49;00m\n",
      "\u001b[33m    \"\"\"\u001b[39;49;00m\n",
      "    \n",
      "    cv_dfs_collection = []\n",
      "    \u001b[34mif\u001b[39;49;00m model_type==\u001b[33m'\u001b[39;49;00m\u001b[33mTfidfVectorizer\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "        models = [\n",
      "        (\u001b[33m'\u001b[39;49;00m\u001b[33mLogisticRegression\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, LogisticRegression(random_state=seed)),\n",
      "        (\u001b[33m'\u001b[39;49;00m\u001b[33mLinearSVC\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, LinearSVC()), \n",
      "        (\u001b[33m'\u001b[39;49;00m\u001b[33mDecisionTreeClassifier\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, DecisionTreeClassifier(random_state=seed)),\n",
      "        \u001b[37m#('KNeighborsClassifier', KNeighborsClassifier()),\u001b[39;49;00m\n",
      "        (\u001b[33m'\u001b[39;49;00m\u001b[33mGaussianNB\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, GaussianNB()), \n",
      "        (\u001b[33m'\u001b[39;49;00m\u001b[33mMultinomialNB\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, MultinomialNB()), \n",
      "        (\u001b[33m'\u001b[39;49;00m\u001b[33mMultinomialNB_prior\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, MultinomialNB(fit_prior=\u001b[34mTrue\u001b[39;49;00m, class_prior=\u001b[34mNone\u001b[39;49;00m)),\n",
      "        (\u001b[33m'\u001b[39;49;00m\u001b[33mRandomForestClassifier\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, RandomForestClassifier(n_estimators=\u001b[34m100\u001b[39;49;00m,  max_depth=\u001b[34m5\u001b[39;49;00m, random_state=seed)),\n",
      "        (\u001b[33m'\u001b[39;49;00m\u001b[33mRandomForestClassifier_200\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, RandomForestClassifier(n_estimators=\u001b[34m200\u001b[39;49;00m,  max_depth=\u001b[34m5\u001b[39;49;00m, random_state=seed))\n",
      "                \u001b[37m#('LogisticRegression_sag', LogisticRegression(solver='sag',random_state=seed)),\u001b[39;49;00m\n",
      "                \u001b[37m#('SVC' , SVC()),#,(gamma=2, C=1)),\u001b[39;49;00m\n",
      "                \u001b[37m#('SVC2' , SVC(gamma=2, C=1)),\u001b[39;49;00m\n",
      "                \u001b[37m#('XGB', XGBClassifier()),\u001b[39;49;00m\n",
      "                \u001b[37m#('KNeighborsClassifier_3', KNeighborsClassifier(n_neighbors=3, weights='uniform', algorithm='auto'))\u001b[39;49;00m\n",
      "        ]\n",
      "    \n",
      "    \u001b[34mif\u001b[39;49;00m model_type==\u001b[33m'\u001b[39;49;00m\u001b[33mCountVectorizer\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "        models = [\n",
      "        (\u001b[33m'\u001b[39;49;00m\u001b[33mLogisticRegression\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, LogisticRegression(random_state=seed)),\n",
      "        (\u001b[33m'\u001b[39;49;00m\u001b[33mLinearSVC\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, LinearSVC()), \n",
      "        (\u001b[33m'\u001b[39;49;00m\u001b[33mDecisionTreeClassifier\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, DecisionTreeClassifier(random_state=seed)),\n",
      "        (\u001b[33m'\u001b[39;49;00m\u001b[33mKNeighborsClassifier\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, KNeighborsClassifier()),\n",
      "        (\u001b[33m'\u001b[39;49;00m\u001b[33mGaussianNB\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, GaussianNB()), \n",
      "        (\u001b[33m'\u001b[39;49;00m\u001b[33mMultinomialNB\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, MultinomialNB()), \n",
      "        (\u001b[33m'\u001b[39;49;00m\u001b[33mMultinomialNB_prior\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, MultinomialNB(fit_prior=\u001b[34mTrue\u001b[39;49;00m, class_prior=\u001b[34mNone\u001b[39;49;00m)),\n",
      "        (\u001b[33m'\u001b[39;49;00m\u001b[33mRandomForestClassifier\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, RandomForestClassifier(n_estimators=\u001b[34m100\u001b[39;49;00m,  max_depth=\u001b[34m5\u001b[39;49;00m, random_state=seed)),\n",
      "        (\u001b[33m'\u001b[39;49;00m\u001b[33mRandomForestClassifier_200\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, RandomForestClassifier(n_estimators=\u001b[34m200\u001b[39;49;00m,  max_depth=\u001b[34m5\u001b[39;49;00m, random_state=seed))\n",
      "                \u001b[37m#('LogisticRegression_sag', LogisticRegression(solver='sag',random_state=seed)),\u001b[39;49;00m\n",
      "                \u001b[37m#('SVC' , SVC()),#,(gamma=2, C=1)),\u001b[39;49;00m\n",
      "                \u001b[37m#('SVC2' , SVC(gamma=2, C=1)),\u001b[39;49;00m\n",
      "                \u001b[37m#('XGB', XGBClassifier()),\u001b[39;49;00m\n",
      "                \u001b[37m#('KNeighborsClassifier_3', KNeighborsClassifier(n_neighbors=3, weights='uniform', algorithm='auto'))\u001b[39;49;00m\n",
      "        ]\n",
      "    results_collection = []\n",
      "    model_desc_collection = []\n",
      "    scoring = [\u001b[33m'\u001b[39;49;00m\u001b[33maccuracy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mprecision_macro\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mrecall_macro\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mf1_macro\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mprecision_weighted\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mrecall_weighted\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mf1_weighted\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\n",
      "    \n",
      "    \u001b[34mfor\u001b[39;49;00m model_desc, model \u001b[35min\u001b[39;49;00m models:\n",
      "        \u001b[37m# Start timer\u001b[39;49;00m\n",
      "        start_model_time = time();\n",
      "        \n",
      "        skf = StratifiedKFold(n_splits=n_splits, shuffle=\u001b[34mTrue\u001b[39;49;00m, random_state=seed)\n",
      "        cv_results = model_selection.cross_validate(model, X_train, y_train, cv=skf, scoring=scoring)\n",
      "        \n",
      "        \u001b[36mprint\u001b[39;49;00m(model_desc)\n",
      "        \u001b[36mprint\u001b[39;49;00m(model)\n",
      "        \u001b[37m# Stop timer\u001b[39;49;00m\n",
      "        end_model_time =  \u001b[36mround\u001b[39;49;00m(time()-start_model_time, \u001b[34m1\u001b[39;49;00m);\n",
      "        \u001b[36mprint\u001b[39;49;00m(end_model_time)\n",
      "        \n",
      "        results_collection.append(cv_results)\n",
      "        model_desc_collection.append(model_desc)\n",
      "        \n",
      "        cv_df = pd.DataFrame(cv_results)\n",
      "        cv_df[\u001b[33m'\u001b[39;49;00m\u001b[33mmodel_desc\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] = model_desc\n",
      "        cv_df[\u001b[33m'\u001b[39;49;00m\u001b[33mmodel_duration\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] = end_model_time\n",
      "        \n",
      "        cv_dfs_collection.append(cv_df)\n",
      "        \n",
      "        df_cv_metric_scores = pd.concat(cv_dfs_collection, ignore_index=\u001b[34mTrue\u001b[39;49;00m)\n",
      "    \n",
      "    \u001b[34mreturn\u001b[39;49;00m df_cv_metric_scores\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mtokenize_TfidfVectorizer\u001b[39;49;00m(X_train, X_test, stop_words, is_bigram:\u001b[34mTrue\u001b[39;49;00m):\n",
      "    \n",
      "    \u001b[34mif\u001b[39;49;00m is_bigram:\n",
      "        word_vectorizer = TfidfVectorizer(\n",
      "                            sublinear_tf=\u001b[34mTrue\u001b[39;49;00m, \u001b[37m# set to true to scale the term frequency in logarithmic scale.\u001b[39;49;00m\n",
      "                            min_df=\u001b[34m5\u001b[39;49;00m,\n",
      "                            stop_words=stop_words,\n",
      "                            \u001b[37m#strip_accents='unicode',\u001b[39;49;00m\n",
      "                            \u001b[37m#token_pattern=r'\\w{1,}',\u001b[39;49;00m\n",
      "                            \u001b[37m#analyzer='word',\u001b[39;49;00m\n",
      "                            ngram_range=(\u001b[34m1\u001b[39;49;00m, \u001b[34m2\u001b[39;49;00m));\n",
      "    \n",
      "    \u001b[34melse\u001b[39;49;00m: \u001b[37m#only-gram\u001b[39;49;00m\n",
      "        \n",
      "        word_vectorizer = TfidfVectorizer(\n",
      "                            sublinear_tf=\u001b[34mTrue\u001b[39;49;00m, \u001b[37m# set to true to scale the term frequency in logarithmic scale.\u001b[39;49;00m\n",
      "                            min_df=\u001b[34m5\u001b[39;49;00m,\n",
      "                            stop_words=stop_words,\n",
      "                            \u001b[37m#strip_accents='unicode',\u001b[39;49;00m\n",
      "                            \u001b[37m#token_pattern=r'\\w{1,}',\u001b[39;49;00m\n",
      "                            \u001b[37m#analyzer='word',\u001b[39;49;00m\n",
      "                            ngram_range=(\u001b[34m1\u001b[39;49;00m, \u001b[34m1\u001b[39;49;00m));\n",
      "\n",
      "    X_train = word_vectorizer.fit_transform(X_train).toarray()\n",
      "    X_test = word_vectorizer.transform(X_test)\n",
      "\n",
      "    \u001b[34mreturn\u001b[39;49;00m {\n",
      "        \u001b[33m'\u001b[39;49;00m\u001b[33mX_train\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: X_train,\n",
      "        \u001b[33m'\u001b[39;49;00m\u001b[33mX_test\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: X_test,\n",
      "        \u001b[33m'\u001b[39;49;00m\u001b[33mword_vectorizer\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: word_vectorizer\n",
      "    }\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mtokenize_CountVectorizer\u001b[39;49;00m(X_train, X_test, stop_words, is_bigram:\u001b[34mTrue\u001b[39;49;00m):\n",
      "    \n",
      "    \u001b[34mif\u001b[39;49;00m is_bigram:\n",
      "        word_vectorizer = CountVectorizer(\n",
      "                            min_df=\u001b[34m5\u001b[39;49;00m,\n",
      "                            stop_words=stop_words,\n",
      "                            \u001b[37m#strip_accents='unicode',\u001b[39;49;00m\n",
      "                            \u001b[37m#token_pattern=r'\\w{1,}',\u001b[39;49;00m\n",
      "                            \u001b[37m#analyzer='word',\u001b[39;49;00m\n",
      "                            ngram_range=(\u001b[34m1\u001b[39;49;00m, \u001b[34m2\u001b[39;49;00m));\n",
      "    \n",
      "    \u001b[34melse\u001b[39;49;00m: \u001b[37m#only-gram\u001b[39;49;00m\n",
      "        \n",
      "        word_vectorizer = CountVectorizer(\n",
      "                            min_df=\u001b[34m5\u001b[39;49;00m,\n",
      "                            stop_words=stop_words,\n",
      "                            \u001b[37m#strip_accents='unicode',\u001b[39;49;00m\n",
      "                            \u001b[37m#token_pattern=r'\\w{1,}',\u001b[39;49;00m\n",
      "                            \u001b[37m#analyzer='word',\u001b[39;49;00m\n",
      "                            ngram_range=(\u001b[34m1\u001b[39;49;00m, \u001b[34m1\u001b[39;49;00m));\n",
      "        \n",
      "    X_train_counts = word_vectorizer.fit_transform(X_train)\n",
      "    tfidf_transformer = TfidfTransformer()\n",
      "    X_train = tfidf_transformer.fit_transform(X_train_counts)\n",
      "    X_test = word_vectorizer.fit_transform(X_test).toarray()\n",
      "\n",
      "    \u001b[34mreturn\u001b[39;49;00m {\n",
      "        \u001b[33m'\u001b[39;49;00m\u001b[33mX_train\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: X_train,\n",
      "        \u001b[33m'\u001b[39;49;00m\u001b[33mX_test\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: X_test,\n",
      "        \u001b[33m'\u001b[39;49;00m\u001b[33mword_vectorizer\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: word_vectorizer\n",
      "    }\n",
      "\n",
      "\u001b[37m#https://www.codementor.io/@rohitagrawalofficialmail/analyzing-text-classification-techniques-on-youtube-data-x5sa1cdvw\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mfeatures_correlated\u001b[39;49;00m (word_vectorizer, _pre_features, df_products, df_products_id, product_to_id, n):\n",
      "    \u001b[33m\"\"\"\u001b[39;49;00m\n",
      "\u001b[33m        This function allows check if the features extracted using TF-IDF vectorization made any sense\u001b[39;49;00m\n",
      "\u001b[33m        find the most correlated unigrams and bigrams for each product\u001b[39;49;00m\n",
      "\u001b[33m            param word_vectorizer: word_vectorizer.fit_transform(X_test).toarray()\u001b[39;49;00m\n",
      "\u001b[33m            param n = features\u001b[39;49;00m\n",
      "\u001b[33m    \"\"\"\u001b[39;49;00m\n",
      "    \u001b[34mfor\u001b[39;49;00m product_id, product \u001b[35min\u001b[39;49;00m \u001b[36msorted\u001b[39;49;00m(product_to_id.items()):\n",
      "        features_chi2 = chi2(_pre_features, df_products_id == product_id)\n",
      "        indices = np.argsort(features_chi2[\u001b[34m0\u001b[39;49;00m])\n",
      "        feature_names = np.array(word_vectorizer.get_feature_names())[indices]\n",
      "        unigrams = [v \u001b[34mfor\u001b[39;49;00m v \u001b[35min\u001b[39;49;00m feature_names \u001b[34mif\u001b[39;49;00m \u001b[36mlen\u001b[39;49;00m(v.split(\u001b[33m'\u001b[39;49;00m\u001b[33m \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)) == \u001b[34m1\u001b[39;49;00m]\n",
      "        bigrams = [v \u001b[34mfor\u001b[39;49;00m v \u001b[35min\u001b[39;49;00m feature_names \u001b[34mif\u001b[39;49;00m \u001b[36mlen\u001b[39;49;00m(v.split(\u001b[33m'\u001b[39;49;00m\u001b[33m \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)) == \u001b[34m2\u001b[39;49;00m]\n",
      "        trigrams = [v \u001b[34mfor\u001b[39;49;00m v \u001b[35min\u001b[39;49;00m feature_names \u001b[34mif\u001b[39;49;00m \u001b[36mlen\u001b[39;49;00m(v.split(\u001b[33m'\u001b[39;49;00m\u001b[33m \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)) == \u001b[34m3\u001b[39;49;00m]\n",
      "\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33m# \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m:\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(product))\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mMost correlated unigrams:\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33m-\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m *\u001b[34m30\u001b[39;49;00m)\n",
      "        \n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33m. \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.format(\u001b[33m'\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m. \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.join(unigrams[-n:])))\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mMost correlated bigrams:\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33m-\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m *\u001b[34m30\u001b[39;49;00m)\n",
      "        \n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33m. \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.format(\u001b[33m'\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m. \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.join(bigrams[-n:])))\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mMost correlated trigrams:\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33m-\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m *\u001b[34m30\u001b[39;49;00m)\n",
      "        \n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33m. \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.format(\u001b[33m'\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m. \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.join(trigrams[-n:])))\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n"
     ]
    }
   ],
   "source": [
    "#directory \n",
    "!pygmentize source_sklearn/train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#from nltk.corpus import stopwords\n",
    "#from nltk.stem import SnowballStemmer\n",
    "\n",
    "#import re\n",
    "#import string\n",
    "#from io import StringIO\n",
    "\n",
    "#complaint_text = df_complaints['complaint_text']\n",
    "#complaint_text\n",
    "#complaint_text = complaint_text.map(lambda complaint_text:  helpers.clean_text(complaint_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train supervised classifiers, we first transformed the `complaint_text` into a vector of numbers so that the algorithms to be used are able to make prediction. In this case, the term Frequency - Reverse Document Frequency (TFIDF) like bag of words to will be used to assess the importance of a word for a complaint in a complaints collection. Como o texto Ã© extenso, conidera-se tambÃ©m a remoÃ§Ã£o das stop words.\n",
    "\n",
    "After removing the punctuation and remove stop words, the importance of a word is determined in terms of its frequency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split test and train data**\n",
    "\n",
    "It should return the follow tuples:\n",
    "\n",
    "* `X_train` `y_train` - selected training features and their corresponding product labels without text clean \n",
    "\n",
    "* `X_test` `y_test)` - selected training features and their corresponding produt labels without text clean \n",
    "\n",
    "* `X_test_clean` `y_test_clean` - selected training features and their corresponding produt labels with text clean \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26         Money transfer, virtual currency, or money ser...\n",
       "217                              Credit card or prepaid card\n",
       "425                                                     Loan\n",
       "448                              Checking or savings account\n",
       "467                                                     Loan\n",
       "                                 ...                        \n",
       "1826949                          Credit card or prepaid card\n",
       "1826979                              Bank account or service\n",
       "1827014                                      Debt collection\n",
       "1827019                                      Debt collection\n",
       "1827272    Money transfer, virtual currency, or money ser...\n",
       "Name: product, Length: 31503, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (31503,) y shape: (31503,) X_train: (25202,) y_train: (25202,) X_test: (6301,) y_test: (6301,)\n",
      "X shape: (31503,) y shape: (31503,) X_train: (25202,) y_train: (25202,) X_test: (6301,) y_test: (6301,)\n"
     ]
    }
   ],
   "source": [
    "is_shuffle=True\n",
    "\n",
    "# split data with clean text\n",
    "is_clean=False\n",
    "X_train, X_test, y_train, y_test = train.split_data(pre_features, products, is_clean, is_shuffle, seed)\n",
    "\n",
    "# split data without clean text\n",
    "is_clean=True\n",
    "X_train_clean, X_test_clean, y_train, y_test = train.split_data(pre_features, products, is_clean, is_shuffle, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Pickling our subsetted dataframe\n",
    "helpers.save_pickle(dest_folder, X_train, 'X_train');\n",
    "helpers.save_pickle(dest_folder, y_train, 'Y_train');\n",
    "helpers.save_pickle(dest_folder, X_test, 'X_test');\n",
    "helpers.save_pickle(dest_folder, y_test, 'y_test');\n",
    "\n",
    "helpers.save_pickle(dest_folder, X_test_clean, 'X_test_clean');\n",
    "helpers.save_pickle(dest_folder, X_train_clean, 'X_train_clean');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1126779    theses are hard inquiries on my report that ne...\n",
       "1446430    i checked my credit report and i found out tha...\n",
       "1761102    on i was charged a 95 00 annual fee for my cit...\n",
       "1490891    equifax refuses to give me a free credit repor...\n",
       "226064     i mailed a certified dispute letter to transun...\n",
       "                                 ...                        \n",
       "732934     i sent some money to my mother on through the ...\n",
       "1794616    in 2018 i bought a phone through and paid 3600...\n",
       "1574504    i was told i could have my loans cut by 50 all...\n",
       "461845     i am enrolled with and have money saved to pay...\n",
       "1532648    received faux notice stating your account is o...\n",
       "Name: complaint_text, Length: 25202, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train\n",
    "X_train_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a bag of words using TF-IDF for the complaints**\n",
    "\n",
    "To create the Bag of Words, I chose to test with **CountVectorizer** and **TfidfVectorizer**.\n",
    "\n",
    "**CountVectorizer**\n",
    "* `: 1-gram only`\n",
    "* `: 1-gram only and text clean`\n",
    "* `: bigram`\n",
    "* `: bigram and text clean`\n",
    "\n",
    "**TfidfVectorizer**\n",
    "* `: 1-gram only`\n",
    "* `: 1-gram only and text clean`\n",
    "* `: bigram`\n",
    "* `: bigram and text clean`\n",
    "\n",
    "Based on the analysis performed by [27] now let us see if the features are correctly extracted from the text data by checking the most important features for each class. Understand the features that are most correlated with each of the products:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each of the 31503 complaints is represented by 10765 features (representing CountVectorizer score of unigrams)\n",
      "------------------------------\n",
      "Each of the 31503 complaints is represented by 10765 features (representing TfidfVectorizer score of unigrams)\n",
      "------------------------------\n",
      "Each of the 31503 complaints is represented by 10765 features (representing CountVectorizer score of unigrams and clean text)\n",
      "------------------------------\n",
      "Each of the 31503 complaints is represented by 10765 features (representing TfidfVectorizer score of unigrams and clean text)\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "#1-gram only\n",
    "is_bigram=False\n",
    "stop_words='english'\n",
    "\n",
    "tokens = train.tokenize_CountVectorizer(X_train, X_test, stop_words, is_bigram)\n",
    "_X_train = tokens['X_train']\n",
    "_X_test = tokens['X_test']\n",
    "_word_vectorizer = tokens['word_vectorizer']\n",
    "helpers.save_pickle(dest_folder, _X_train, 'train_tokenize_CountVectorizer_1');\n",
    "helpers.save_pickle(dest_folder, _X_test, 'test_tokenize_CountVectorizer_1');\n",
    "helpers.save_pickle(dest_folder, _word_vectorizer, 'word_vectorizer_tokenize_CountVectorizer_1');\n",
    "# Transform each complaint into a vector\n",
    "_pre_features = _word_vectorizer.fit_transform(pre_features).toarray()\n",
    "print(\"Each of the %d complaints is represented by %d features (representing CountVectorizer score of unigrams)\" %(_pre_features.shape))\n",
    "print('-' *30)\n",
    "#train.features_correlated(_word_vectorizer,_pre_features, df_products, df_products_id, product_to_id, 5)\n",
    "#print('-' *30)\n",
    "#print('-' *30)\n",
    "\n",
    "tokens = train.tokenize_TfidfVectorizer(X_train, X_test, stop_words, is_bigram)\n",
    "_X_train = tokens['X_train']\n",
    "_X_test = tokens['X_test']\n",
    "_word_vectorizer = tokens['word_vectorizer']\n",
    "helpers.save_pickle(dest_folder, _X_train, 'train_tokenize_TfidfVectorizer_1');\n",
    "helpers.save_pickle(dest_folder, _X_test, 'test_tokenize_TfidfVectorizer_1');\n",
    "helpers.save_pickle(dest_folder, _word_vectorizer, 'word_vectorizer_tokenize_TfidfVectorizer_1');\n",
    "# Transform each complaint into a vector\n",
    "_pre_features = _word_vectorizer.fit_transform(pre_features).toarray()\n",
    "print(\"Each of the %d complaints is represented by %d features (representing TfidfVectorizer score of unigrams)\" %(_pre_features.shape))\n",
    "print('-' *30)\n",
    "#train.features_correlated(_word_vectorizer,_pre_features, df_products, df_products_id, product_to_id, 5)\n",
    "#print('-' *30)\n",
    "#print('-' *30)\n",
    "\n",
    "\n",
    "#1-gram only and text clean\n",
    "# split data\n",
    "is_bigram=False\n",
    "stop_words='english'\n",
    "\n",
    "tokens = train.tokenize_CountVectorizer(X_train_clean, X_test_clean, stop_words, is_bigram)\n",
    "_X_train = tokens['X_train']\n",
    "_X_test = tokens['X_test']\n",
    "_word_vectorizer = tokens['word_vectorizer']\n",
    "helpers.save_pickle(dest_folder, _X_train, 'train_tokenize_CountVectorizer_1_clean');\n",
    "helpers.save_pickle(dest_folder, _X_test, 'test_tokenize_CountVectorizer_1_clean');\n",
    "helpers.save_pickle(dest_folder, _word_vectorizer, 'word_vectorizer_tokenize_CountVectorizer_1_clean');\n",
    "\n",
    "# Transform each complaint into a vector\n",
    "_pre_features = _word_vectorizer.fit_transform(pre_features).toarray()\n",
    "print(\"Each of the %d complaints is represented by %d features (representing CountVectorizer score of unigrams and clean text)\" %(_pre_features.shape))\n",
    "print('-' *30)\n",
    "#train.features_correlated(_word_vectorizer,_pre_features, df_products, df_products_id, product_to_id, 5)\n",
    "#print('-' *30)\n",
    "#print('-' *30)\n",
    "\n",
    "tokens = train.tokenize_TfidfVectorizer(X_train_clean, X_test_clean, stop_words, is_bigram)\n",
    "_X_train = tokens['X_train']\n",
    "_X_test = tokens['X_test']\n",
    "_word_vectorizer = tokens['word_vectorizer']\n",
    "helpers.save_pickle(dest_folder, _X_train, 'train_tokenize_TfidfVectorizer_1_clean');\n",
    "helpers.save_pickle(dest_folder, _X_test, 'test_tokenize_TfidfVectorizer_1_clean');\n",
    "helpers.save_pickle(dest_folder, _word_vectorizer, 'word_vectorizer_tokenize_TfidfVectorizer_1_clean');\n",
    "\n",
    "# Transform each complaint into a vector\n",
    "_pre_features = _word_vectorizer.fit_transform(pre_features).toarray()\n",
    "print(\"Each of the %d complaints is represented by %d features (representing TfidfVectorizer score of unigrams and clean text)\" %(_pre_features.shape))\n",
    "print('-' *30)\n",
    "#train.features_correlated(_word_vectorizer,_pre_features, df_products, df_products_id, product_to_id, 5)\n",
    "#print('-' *30)\n",
    "#print('-' *30)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each of the 31503 complaints is represented by 84278 features (representing CountVectorizer score of bigrams)\n",
      "------------------------------\n",
      "Each of the 31503 complaints is represented by 84278 features (representing TfidfVectorizer score of bigrams)\n",
      "------------------------------\n",
      "Each of the 31503 complaints is represented by 84278 features (representing CountVectorizer score of bigrams and clean text)\n",
      "------------------------------\n",
      "Each of the 31503 complaints is represented by 84278 features (representing TfidfVectorizer score of bigrams and clean text)\n",
      "# 'Bank account or service':\n",
      "Most correlated unigrams:\n",
      "------------------------------\n",
      ". branch\n",
      ". hsa\n",
      ". citigold\n",
      ". overdraft\n",
      ". scottrade\n",
      "Most correlated bigrams:\n",
      "------------------------------\n",
      ". checking account\n",
      ". xxxx overdraft\n",
      ". overdraft fees\n",
      ". citigold checking\n",
      ". scottrade bank\n",
      "Most correlated trigrams:\n",
      "------------------------------\n",
      ". \n",
      "\n",
      "\n",
      "# 'Checking or savings account':\n",
      "Most correlated unigrams:\n",
      "------------------------------\n",
      ". branch\n",
      ". atm\n",
      ". checking\n",
      ". overdraft\n",
      ". bonus\n",
      "Most correlated bigrams:\n",
      "------------------------------\n",
      ". checking savings\n",
      ". overdraft fee\n",
      ". overdraft fees\n",
      ". checking account\n",
      ". 00 bonus\n",
      "Most correlated trigrams:\n",
      "------------------------------\n",
      ". \n",
      "\n",
      "\n",
      "# 'Credit card or prepaid card':\n",
      "Most correlated unigrams:\n",
      "------------------------------\n",
      ". citi\n",
      ". express\n",
      ". amex\n",
      ". rewards\n",
      ". card\n",
      "Most correlated bigrams:\n",
      "------------------------------\n",
      ". credit limit\n",
      ". minimum payment\n",
      ". annual fee\n",
      ". american express\n",
      ". credit card\n",
      "Most correlated trigrams:\n",
      "------------------------------\n",
      ". \n",
      "\n",
      "\n",
      "# 'Credit reporting, repair, or other':\n",
      "Most correlated unigrams:\n",
      "------------------------------\n",
      ". experian\n",
      ". credit\n",
      ". reporting\n",
      ". equifax\n",
      ". report\n",
      "Most correlated bigrams:\n",
      "------------------------------\n",
      ". credit reporting\n",
      ". credit file\n",
      ". credit bureaus\n",
      ". identity theft\n",
      ". credit report\n",
      "Most correlated trigrams:\n",
      "------------------------------\n",
      ". \n",
      "\n",
      "\n",
      "# 'Debt collection':\n",
      "Most correlated unigrams:\n",
      "------------------------------\n",
      ". collector\n",
      ". owe\n",
      ". collect\n",
      ". collection\n",
      ". debt\n",
      "Most correlated bigrams:\n",
      "------------------------------\n",
      ". trying collect\n",
      ". debt collector\n",
      ". debt collection\n",
      ". collect debt\n",
      ". collection agency\n",
      "Most correlated trigrams:\n",
      "------------------------------\n",
      ". \n",
      "\n",
      "\n",
      "# 'Loan':\n",
      "Most correlated unigrams:\n",
      "------------------------------\n",
      ". student\n",
      ". repayment\n",
      ". loans\n",
      ". loan\n",
      ". navient\n",
      "Most correlated bigrams:\n",
      "------------------------------\n",
      ". based repayment\n",
      ". loan forgiveness\n",
      ". student loan\n",
      ". student loans\n",
      ". income based\n",
      "Most correlated trigrams:\n",
      "------------------------------\n",
      ". \n",
      "\n",
      "\n",
      "# 'Money transfer, virtual currency, or money service':\n",
      "Most correlated unigrams:\n",
      "------------------------------\n",
      ". credit\n",
      ". transfer\n",
      ". coinbase\n",
      ". money\n",
      ". paypal\n",
      "Most correlated bigrams:\n",
      "------------------------------\n",
      ". wire transfer\n",
      ". cash app\n",
      ". western union\n",
      ". bank account\n",
      ". credit report\n",
      "Most correlated trigrams:\n",
      "------------------------------\n",
      ". \n",
      "\n",
      "\n",
      "# 'Mortgage':\n",
      "Most correlated unigrams:\n",
      "------------------------------\n",
      ". ocwen\n",
      ". foreclosure\n",
      ". escrow\n",
      ". modification\n",
      ". mortgage\n",
      "Most correlated bigrams:\n",
      "------------------------------\n",
      ". short sale\n",
      ". escrow account\n",
      ". mortgage payment\n",
      ". mortgage company\n",
      ". loan modification\n",
      "Most correlated trigrams:\n",
      "------------------------------\n",
      ". \n",
      "\n",
      "\n",
      "# 'Other financial service':\n",
      "Most correlated unigrams:\n",
      "------------------------------\n",
      ". global\n",
      ". fedloanhelp\n",
      ". consolidate\n",
      ". certegy\n",
      ". lexington\n",
      "Most correlated bigrams:\n",
      "------------------------------\n",
      ". money order\n",
      ". credit repair\n",
      ". client solutions\n",
      ". global client\n",
      ". lexington law\n",
      "Most correlated trigrams:\n",
      "------------------------------\n",
      ". \n",
      "\n",
      "\n",
      "------------------------------\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# bigram\n",
    "is_bigram=True\n",
    "stop_words='english'\n",
    "\n",
    "tokens = train.tokenize_CountVectorizer(X_train, X_test, stop_words, is_bigram)\n",
    "_X_train = tokens['X_train']\n",
    "_X_test = tokens['X_test']\n",
    "_word_vectorizer = tokens['word_vectorizer']\n",
    "helpers.save_pickle(dest_folder, _X_train, 'train_tokenize_CountVectorizer_2');\n",
    "helpers.save_pickle(dest_folder, _X_test, 'test_tokenize_CountVectorizer_2');\n",
    "helpers.save_pickle(dest_folder, _word_vectorizer, 'word_vectorizer_tokenize_CountVectorizer_2');\n",
    "\n",
    "# Transform each complaint into a vector\n",
    "_pre_features = _word_vectorizer.fit_transform(pre_features).toarray()\n",
    "print(\"Each of the %d complaints is represented by %d features (representing CountVectorizer score of bigrams)\" %(_pre_features.shape))\n",
    "print('-' *30)\n",
    "#train.features_correlated(_word_vectorizer,_pre_features, df_products, df_products_id, product_to_id, 5)\n",
    "#print('-' *30)\n",
    "#print('-' *30)\n",
    "\n",
    "tokens = train.tokenize_TfidfVectorizer(X_train, X_test, stop_words, is_bigram)\n",
    "_X_train = tokens['X_train']\n",
    "_X_test = tokens['X_test']\n",
    "_word_vectorizer = tokens['word_vectorizer']\n",
    "helpers.save_pickle(dest_folder, _X_train, 'train_tokenize_TfidfVectorizer_2');\n",
    "helpers.save_pickle(dest_folder, _X_test, 'test_tokenize_TfidfVectorizer_2');\n",
    "helpers.save_pickle(dest_folder, _word_vectorizer, 'word_vectorizer_tokenize_TfidfVectorizer_2');\n",
    "# Transform each complaint into a vector\n",
    "_pre_features = _word_vectorizer.fit_transform(pre_features).toarray()\n",
    "print(\"Each of the %d complaints is represented by %d features (representing TfidfVectorizer score of bigrams)\" %(_pre_features.shape))\n",
    "print('-' *30)\n",
    "#train.features_correlated(_word_vectorizer,_pre_features, df_products, df_products_id, product_to_id, 5)\n",
    "#print('-' *30)\n",
    "#print('-' *30)\n",
    "\n",
    "\n",
    "### bigram and text clean\n",
    "is_bigram=True\n",
    "stop_words='english'\n",
    "\n",
    "tokens = train.tokenize_CountVectorizer(X_train_clean, X_test_clean, stop_words, is_bigram)\n",
    "_X_train = tokens['X_train']\n",
    "_X_test = tokens['X_test']\n",
    "_word_vectorizer = tokens['word_vectorizer']\n",
    "helpers.save_pickle(dest_folder, _X_train, 'train_tokenize_CountVectorizer_2_clean');\n",
    "helpers.save_pickle(dest_folder, _X_test, 'test_tokenize_CountVectorizer_2_clean');\n",
    "helpers.save_pickle(dest_folder, _word_vectorizer, 'word_vectorizer_tokenize_CountVectorizer_2_clean');\n",
    "# Transform each complaint into a vector\n",
    "_pre_features = _word_vectorizer.fit_transform(pre_features).toarray()\n",
    "print(\"Each of the %d complaints is represented by %d features (representing CountVectorizer score of bigrams and clean text)\" %(_pre_features.shape))\n",
    "print('-' *30)\n",
    "#train.features_correlated(_word_vectorizer,_pre_features, df_products, df_products_id, product_to_id, 5)\n",
    "#print('-' *30)\n",
    "#print('-' *30)\n",
    "\n",
    "tokens = train.tokenize_TfidfVectorizer(X_train_clean, X_test_clean, stop_words, is_bigram)\n",
    "_X_train = tokens['X_train']\n",
    "_X_test = tokens['X_test']\n",
    "_word_vectorizer = tokens['word_vectorizer']\n",
    "helpers.save_pickle(dest_folder, _X_train, 'train_tokenize_TfidfVectorizer_2_clean');\n",
    "helpers.save_pickle(dest_folder, _X_test, 'test_tokenize_TfidfVectorizer_2_clean');\n",
    "helpers.save_pickle(dest_folder, _word_vectorizer, 'word_vectorizer_tokenize_TfidfVectorizer_2_clean');\n",
    "# Transform each complaint into a vector\n",
    "_pre_features = _word_vectorizer.fit_transform(pre_features).toarray()\n",
    "print(\"Each of the %d complaints is represented by %d features (representing TfidfVectorizer score of bigrams and clean text)\" %(_pre_features.shape))\n",
    "train.features_correlated(_word_vectorizer,_pre_features, df_products, df_products_id, product_to_id, 5)\n",
    "print('-' *30)\n",
    "print('-' *30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(0, 'Bank account or service'), (1, 'Checking or savings account'), (2, 'Credit card or prepaid card'), (3, 'Credit reporting, repair, or other'), (4, 'Debt collection'), (5, 'Loan'), (6, 'Money transfer, virtual currency, or money service'), (7, 'Mortgage'), (8, 'Other financial service')])\n"
     ]
    }
   ],
   "source": [
    "print(product_to_id.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Up Next\n",
    "\n",
    "This notebook is just about data pre-processing and feature engineering.\n",
    "\n",
    "Due to the fact that this dataset is quite large, I have already tried at this stage to reduce the data subset by about 97% based on the narratives of the complaints. \n",
    "\n",
    "In the next few notebooks, I'll use this data to train and test a complete complaint classifier.\n",
    "\n",
    "For that I'll use the fourth notebook **04_data_training**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------ END 03 Data Pre-Processing and Feature Engineering --------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
